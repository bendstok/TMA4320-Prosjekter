{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Skrevet av: Lasse Matias Dragsjø, Bendik Kvamme Stokland, og Thomas Olaussen.\n",
    "\n",
    "# Dictionary learning\n",
    "\n",
    "I denne rapporten ser vi på det som kalles for \"Dictionary learning\", og hvordan en maskin kan gjenkjenne fra hverandre to bilder av ulike tall, 0, og 1. <br>\n",
    "Vi ser først gjennom noen matematiske prosesser for å forstå hvordan vi kan utføre dictionary learning. <br>\n",
    "Så bruker vi data fra MNIST til å utføre dictionary learning, og ser hvordan den projekterer nye bilder til dictionary-en (ordboka) den har lært. <br>\n",
    "Til slutt ser vi på hvordan maskinen klassifiserer mange ulike tallbilder i dybde. <br> <br>\n",
    "\n",
    "Først undersøker vi matematikken. Matrisene A representerer sett med \"bilder\", der hver kolonne skal representere et bilde. <br>\n",
    "Disse bildene kan brukes til å trene opp datamaskinen, og til å få dem i maskinens dictionary. <br>\n",
    "Kolonnevektorene b representerer nye bilder. <br>\n",
    "Disse brukes til å teste hvordan maskinen ser på nye bilder i forhold til dictionary-en sin, altså hvordan den klassifiserer de nye bildene.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importerer biblioteker\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os \n",
    "\n",
    "# Gjør figurer manuelt større\n",
    "plt.rcParams['figure.figsize'] = [12, 8]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Oppgave 1a\n",
    "Først skriver vi ned vektorene, som vi skal bruke i denne delen av oppgaven"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Skriver inn test-datasetter A1 og A2, hver med kolonner som datapunkter\n",
    "A1 = np.array([[1000, 1], [0, 1], [0, 0]])\n",
    "A2 = np.array([[1, 0, 0], [1, 0, 0], [0, 0, 1]])\n",
    "\n",
    "#Skriver inn test-vektorer, og setter det sammen til en matrise\n",
    "b1 = np.array([[2], [1], [0]])\n",
    "b2 = np.array([[0], [0], [1]])\n",
    "b3 = np.array([[0], [1], [0]])\n",
    "B = np.concatenate((b1, b2, b3), axis=1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Det første vi gjør, er å åpne opp A1 ved å regne ut dens SVD: A = U @ S @ Vt. U er dens dictionary W, mens S @ Vt er dens vektmatrise H.\n",
    "Vi undersøker dens egenskaper\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regner ut SVD\n",
    "U, S, Vt = np.linalg.svd(A1, full_matrices = False)\n",
    "\n",
    "# Printer ut svd-matrisene\n",
    "print(f\"U =\\n{U} \\n\")\n",
    "print(f\"Formen på U: {U.shape}\\n\")\n",
    "print(f\"S (egenvektorene) =\\n{S} \\n\")\n",
    "print(f\"Formen på S: {S.shape}\\n\")\n",
    "print(f\"Vt =\\n{Vt} \\n\")\n",
    "print(f\"Formen på Vt: {Vt.shape}\\n\")\n",
    "\n",
    "# Gjør S sine egenvektorer til en matrise. (FS = Full S)\n",
    "FS = np.diag(S)\n",
    "\n",
    "# Rekonstruerer, og printer\n",
    "A = U @ FS @ Vt\n",
    "print(f\"A1 rekonstruert =\\n{A}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Her ser vi at U er på formen (3, 2).\n",
    "Vanligvis skal den være (3, 3). det viser oss at den siste kolonnen var bare fyllt med 0, og er dermed ubrukelig for oss. <br>\n",
    "Dette ser vi er tilfelle, fordi ved å rekonstruere A1, ser vi at vi får samme resultat. <br>\n",
    "Vi finner vi ut hvor viktig de to andre kolonnene er til å rekonstruere A."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regner ut SVD\n",
    "U, S, Vt = np.linalg.svd(A1, full_matrices = False)\n",
    "\n",
    "# Fjerner kolonne 2\n",
    "U[:,1] = 0\n",
    "\n",
    "# Rekonstruerer, og printer\n",
    "A = U @ FS @ Vt\n",
    "print(f\"A1 rekonstruert, uten U[:,1] =\\n{A}\\n\")\n",
    "\n",
    "\n",
    "\n",
    "# Henter svd\n",
    "U, S, Vt = np.linalg.svd(A1, full_matrices = False)\n",
    "\n",
    "# Fjerner kolonne 2\n",
    "U[:,0] = 0\n",
    "\n",
    "# Rekonstruerer, og printer\n",
    "A = U @ FS @ Vt\n",
    "print(f\"A1 rekonstruert, uten U[:,0] =\\n{A}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vi ser at ved å fjerne kolonne 2, får vi omtrent samme svar, bortsett fra indeks A[1][1], som er nå 10^-6, og ikke 1. <br>\n",
    "Med første kolonne vekk istedenfor, får vi en matrise som ikke på noen måte har de samme verdiene der verdiene ikke er 0. <br>\n",
    "Det viser oss at den første kolonnen er viktigst for å rekonstruere matrisen. <br>\n",
    "Det er fordi np.linalg.svd sorterer kolonnene fra mest viktig til minst viktig."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Oppgave 1b\n",
    "Nå sjekker vi A2, om hva redusering av dens U-kolonner vil gjøre med rekonstrueringen\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Henter svd\n",
    "U, S, Vt = np.linalg.svd(A2, full_matrices = False)\n",
    "\n",
    "# Printer ut svd-matrisene\n",
    "print(f\"U =\\n{U} \\n\")\n",
    "print(f\"Formen på U: {U.shape}\\n\")\n",
    "print(f\"S (egenvektorene) =\\n{S} \\n\")\n",
    "print(f\"Formen på S: {S.shape}\\n\")\n",
    "print(f\"Vt =\\n{Vt} \\n\")\n",
    "print(f\"Formen på Vt: {Vt.shape}\\n\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Her ser vi at S har bare 0 ved dens tredje kolonne.<br>\n",
    "Det vi gi FS @ Vt som har sin tredje rad fylt med bare 0. <br>\n",
    "Det vil gjøre den tredje U-kolonnen ubrukelig. <br>\n",
    "Dermed kan vi fjerne denne U-kolonnen, og de korresponderende delene ved S, og Vt, og likevel få den samme matrisen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fjerner kolonne 3\n",
    "U[:,2] = 0\n",
    "\n",
    "# Gjør diagonalvektoren til en matrise\n",
    "FS = np.diag(S)\n",
    "\n",
    "# Rekonstruerer, og printer\n",
    "A = U @ FS @ Vt\n",
    "print(f\"A2 rekonstruert, uten U[:,2] =\\n{A}\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Denne er nøyaktig den samme som den originale A2, som bekrefter det vi sa før. <br>\n",
    "\n",
    "Vi ser at slik redusering kan spare oss plass og tid om vi ønsker full rekonstruering, eller rask og nesten perfect rekonstruering.(Små singulærverdier spiller mindre rolle i rekonstrueringen av den original matrisen) <br>\n",
    "Vi skriver en funksjon til å gjøre dette."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def truncSVD(A, d):\n",
    "    \n",
    "    \"\"\"\n",
    "    Gjør et SVD med de d viktigste leddene i matrisen, altså et trunktert versjon av vanlig SVD-regning,\n",
    "    \n",
    "    Input:\n",
    "    A: Datasett-martise\n",
    "    d: Antall U-kolonner/S-singulærvektorer/V-rader som skal brukes\n",
    "    \n",
    "    Output:\n",
    "    W: Dictionaries\n",
    "    H: Vekt på dictionariesene\n",
    "    \"\"\"\n",
    "    \n",
    "    # Regner ut full SVD\n",
    "    U, S, Vt = np.linalg.svd(A, full_matrices = False)\n",
    "\n",
    "    # Velger de første d relevante vektorer og verdier\n",
    "    U = U[:, :d]\n",
    "    S = S[:d]\n",
    "    Vt = Vt[:d]\n",
    "    \n",
    "    # Gjør diagonalvektoren til en matrise\n",
    "    FS = np.diag(S)\n",
    "    \n",
    "    # Setter inn dictionary og vekt, og returnerer\n",
    "    W = U\n",
    "    H = FS @ Vt\n",
    "    return W, H, S, FS, Vt"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Oppgave 1c\n",
    "Nå ønsker vi å projektere test-datasettene til de ortogonale dictionaries. <br>\n",
    "Slik kan maskinen dra inn nye datasett til sine dictionaries. <br>\n",
    "Vi tester så dens projeksjon med test-matrisen B på den."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def orthproj(W, B):\n",
    "    \n",
    "    \"\"\"\n",
    "    Tar inn et dictionary med ortogonale kolonner W og et sett med kolonner B og prosjekterer B på W.\n",
    "    \n",
    "    Input:\n",
    "    W: Dictionary med ortogonale kolonner\n",
    "    B: Datasett-matrise, representerer treningsbilder eller testbilder\n",
    "    \n",
    "    Output:\n",
    "    orthproj: En projektert versjon av B på W\n",
    "    \"\"\"\n",
    "    \n",
    "    #Transponerer W\n",
    "    Wt = np.transpose(W)\n",
    "    \n",
    "    #Projekterer B på W, og returnerer\n",
    "    orthproj = W @ Wt @ B\n",
    "    return orthproj\n",
    "\n",
    "\n",
    "# Henter W1, og printer projeksjonen for B på W1\n",
    "W1 = truncSVD(A1, 3)[0]\n",
    "print(f\"Projeksjon av B på W1 =\\n{orthproj(W1, B)}\\n\")\n",
    "\n",
    "# Henter W2, og printer projeksjonen for B på W1\n",
    "W2 = truncSVD(A2, 3)[0]\n",
    "print(f\"Projeksjon av B på W2 =\\n{orthproj(W2, B)}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Disse verdiene viser oss projeksjonen av B på W1 og W2. <br>\n",
    "\n",
    "Nå finner vi deres distanse; distansen fra datasett-matrisene til våre dictionaries. <br>\n",
    "Distansen brukes til å se hvor nerme matrisene matcher dictionariesene. <br>\n",
    "Vi tester så dens distance med test-matrisen B."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ortdist(W, B):\n",
    "    \n",
    "    \"\"\"\n",
    "    Regner ut kolonnevis avstand fra matrise B til dictionary W.\n",
    "    \n",
    "    Input:\n",
    "    W: Dictionary med ortogonale kolonner\n",
    "    B: Datasett-matrise, representerer treningsbilder eller testbilder\n",
    "    \n",
    "    Output:\n",
    "    dist: Distanse fra A til W.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Lager en distansevektor, og setter dem 0. Henter så projeksjonen fra B til W\n",
    "    dist = np.zeros(len(B[0]))\n",
    "    proj = orthproj(W, B)\n",
    "    \n",
    "    #Regner ut distansene til hvert kolonne, og returnerer deres avstand\n",
    "    for i in range(len(dist)):\n",
    "        dist[i] = np.linalg.norm(B[:,i] - proj[:,i])\n",
    "    return dist\n",
    "\n",
    "# Printer projeksjonen for B på W1 og W2\n",
    "print(f\"Distansen fra B til W1 =\\n{ortdist(W1, B)}\\n\")\n",
    "print(f\"Distansen fra B til W2 =\\n{ortdist(W2, B)}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Her ser vi at distansen fra B til W1, kolonnevis, er [0, 1, 0]. <br>\n",
    "Dette viser oss at b1  og b2 er inni W1, mens b2 er utenfor W1. <br>\n",
    "Dette er riktig svar ifølge oppgaveskjemaet vi følger. <br>\n",
    "For W2, ser vi at alle kolonnene i B er inni W2.\n",
    "\n",
    "### Oppgave 1d\n",
    "Det kan ta lang tid å trene opp en maskin pga. at en SVD kan ta lang tid å renge ut. <br>\n",
    "Derfor gjør vi også en ikke-negativ fremgang til projeksjon og distansemåling. <br>\n",
    "Vi lager projeksjonsfunksjonen først.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nnproj(W, B, maxiter=50, safeDiv=10e-10):\n",
    "    \n",
    "    \"\"\"\n",
    "    Tar inn et ikke-negativ dictionary W og matrise A og returnerer den ikke negative projeksjonen av B på W.\n",
    "    \n",
    "    Input:\n",
    "    W: Ikke-negativ dictionary\n",
    "    B: Ikke-negativ datasett-matrise, representerer treningsbilder eller testbilder\n",
    "    maxiter: Antall iterasjoner brukt for å regne ut den ikke-negative vekt-matrisen H\n",
    "    safeDiv: Konstant ledd i divisor for å unngå null-divisjon\n",
    "    \n",
    "    Output:\n",
    "    proj: Den ikke-negative projeksjonen av B på W.\n",
    "    \"\"\"\n",
    "    \n",
    "    #Velger tilfeldlige verdier på H (vekt-matrisen) med verdier fra 0 til 1. Brukes til konvergens til å få den ekte H-matrisen = Wt @ B\n",
    "    H = np.random.uniform(0, 1, [len(W[0,:]), len(B[0])])\n",
    "    \n",
    "    #Transponerer W, og henter inn hjelpeverdiene WtB og WtW\n",
    "    Wt = np.transpose(W)\n",
    "    WtB = Wt@B\n",
    "    WtW = Wt@W\n",
    "    \n",
    "    # Itererer maxiter ganger for å konvergere H til den ekte H-matrisen.\n",
    "    for k in range(maxiter):\n",
    "        H = H*WtB/(WtW@H+safeDiv)\n",
    "    \n",
    "    #projekterer B på W, og returnerer projeksonen\n",
    "    proj = W@H\n",
    "    return proj, H\n",
    "\n",
    "# Printer projeksjonene fra B på A1 og A2, og A-enes vekter:\n",
    "print(f\"Projeksjonen av B på A1, ikke-negativt, =\\n{nnproj(A1, B)[0]}\\n\")\n",
    "print(f\"Vektene til A1, ikke-negativt, =\\n{nnproj(A1, B)[1]}\\n\")\n",
    "print(f\"Projeksjonen av B på A2, ikke-negativt, =\\n{nnproj(A2, B)[0]}\\n\")\n",
    "print(f\"Vektene til A2, ikke-negativt, =\\n{nnproj(A2, B)[1]}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Her ser vi projeksjonene, og vektene. Senere vil vi se at disse gir de riktige verdiene, og viser dermed at denne algoritmen funker. <br>\n",
    "Nå ser vi på distansen fra B til A."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nndist(W, B):\n",
    "    \n",
    "    \"\"\"\n",
    "    Regner ut kolonnevis avstand fra ikke-negative matrise B til ikke-negativ dictionary W.\n",
    "    \n",
    "    Input:\n",
    "    W: Ikke-negativ dictionary\n",
    "    B: Ikke-negativ datasett-matrise, representerer treningsbilder eller testbilder\n",
    "    \n",
    "    Output:\n",
    "    dist: Distanse fra B til W.\n",
    "    \"\"\"\n",
    "    # Lager en distansevektor, og setter dem 0. Henter så projeksjonen fra B til W\n",
    "    dist = np.zeros(len(B[0]))\n",
    "    proj = nnproj(W, B)[0]\n",
    "    \n",
    "    #Regner ut distansene til hvert kolonne, og returnerer deres avstand\n",
    "    for i in range(len(dist)):\n",
    "        dist[i] = np.linalg.norm(B[:,i] - proj[:,i])\n",
    "    return dist\n",
    "\n",
    "\"\"\"Tester de forskjellige distanse funksjonene\"\"\"\n",
    "print(f\"Distansen fra B til A1, ikke-negativt, =\\n{nndist(A1, B)}\\n\")\n",
    "print(f\"Distansen fra B til A2, ikke-negativt, =\\n{nndist(A2, B)}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Merk at vi her har distansen A til B, og ikke W til B. <br>\n",
    "Her ser vi at distansen fra B til A1, kolonnevis, er [0, 1, 1/Sq(2)]. <br>\n",
    "Dette viser oss at b1 er inni A1, mens b2 og b3 er utenfor A1. <br>\n",
    "Vi ser her at b3 er innenfor spennet av SVD A1, men ikke i kjeglen av den ikke-negative A1. <br>\n",
    "Dette er riktig svar ifølge oppgaveskjemaet vi følger. <br>\n",
    "For A2, ser vi neglisjerbart de samme verdiene, som også er forskjellig fra den vanlige SVD A2."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Oppgave 2a\n",
    "Nå som vi har matematikken nede og testet, begynner vi med MNIST dataset. <br>\n",
    "Vi laster det ned, og printer ut de 16 første 0-ene.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finner 'veien' til der python filen er på din maskin, for å finne\n",
    "# train og test filene\n",
    "# Altså, må train og test filene være i samme mappe som denne fila\n",
    "try:\n",
    "    dir_path = os.path.dirname(os.path.realpath(__file__))\n",
    "except:\n",
    "    print(\"Could not find dir_path. If using jupyter notebook, ignore\")\n",
    "    train = np.load('train.npy')/255.0\n",
    "    test = np.load('test.npy')/255.0\n",
    "else:\n",
    "    train = np.load(dir_path + '/train.npy')/255.0\n",
    "    test = np.load(dir_path + '/test.npy')/255.0\n",
    "\n",
    "# Kvadratisk bildeplottingsfunksjon\n",
    "def plotimgs(imgs, nplot = 4):    \n",
    "    \"\"\"\n",
    "    Plotter de første nplot*nplot bildene i imgs på et nplot*nplot grid.\n",
    "    Antar høyde=bredde, og at bildene er lagret kolonnevis.\n",
    "    \n",
    "    Input:\n",
    "    imgs: (høyde=bredde,N) array som inneholder bildene. N > nplot**2\n",
    "    nplot: Heltall. nplot**2 bilder vil bli plottete\n",
    "    \n",
    "    Output:\n",
    "    Plot av de første nplot*nplot bildene i imgs på et nplot*nplot grid.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Henter antall bilder, og lengden på bildene \n",
    "    n = imgs.shape[1]\n",
    "    m = int(np.sqrt(imgs.shape[0]))\n",
    "\n",
    "    #sjekker om det er nok bilder til at de kan plottes\n",
    "    assert(n >= nplot**2), \"Need amount of data in matrix N >= nplot**2\"\n",
    "\n",
    "    # Initialiserer subplots\n",
    "    fig, axes = plt.subplots(nplot,nplot)\n",
    "\n",
    "    # Setter bakgrunnsfargen\n",
    "    plt.gcf().set_facecolor(\"lightgray\")\n",
    "\n",
    "    # Itererer over bildene\n",
    "    for idx in range(nplot**2):\n",
    "\n",
    "        # Bryter av hvis vi går utenfor arrayet\n",
    "        if idx >= n:\n",
    "            break\n",
    "\n",
    "        # Indekser\n",
    "        i = idx//nplot; j = idx%nplot\n",
    "\n",
    "        # Fjerner akse\n",
    "        axes[i,j].axis('off')\n",
    "        axes[i,j].imshow(imgs[:,idx].reshape((m,m)), cmap = \"gray\")\n",
    "    \n",
    "    # Plotter\n",
    "    fig.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "plotimgs(train[:,0,:], nplot=4)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Her ser vi de første 16 0-ene. nå bruker vi 0-ene\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Oppgave 2b\n",
    "Nå ser vi litt på deres SVD, egenskaper. <br>\n",
    "Vi regner ut deres SVD, og plotter deres 16 første dictionaries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 1000 # Antall datapunkter\n",
    "c = 0 # Klasse\n",
    "d = 16 # 16 viktigste kolonner\n",
    "\n",
    "A = train[:,c,:n]\n",
    "W, H, S, FS, Vt = truncSVD(A, d)\n",
    "\n",
    "plotimgs(W, nplot = 4)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Her ser vi de 16 første U-kolonnene. <br>\n",
    "Merk at disse ikke er de sammen som de første 0-bildene. <br>\n",
    "Vi ser at disse bildene inneholder viktige egenskaper som tallet 0 har, og at dens egenskaper blir mindre og mindre representerende for tallet 0. <br>\n",
    "\n",
    "Vi ser på dens singulærvektorer plottet logaritmisk vis for å mer innsikt i dem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.semilogy(S)\n",
    "plt.title(\"Verdien av en singulær verdi mot hvilken singulærverdi\")\n",
    "plt.ylabel(\"Verdi Singulærverdi\")\n",
    "plt.xlabel(\"N - Hvilken singulærverdi\")\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotten vise oss at de aller første bildene har store singulæregenvektorer. <br>\n",
    "Den viser at de synker kraftig ned først, men etterpå går den ganske sakte nedover, med mange singulærvektorer som er ontrent det samme. <br>\n",
    "Hvis vi hadde større d, ville vi ha sett at den begynner å gå kraftig ned igjen, helt til at den krasjer til neglisjerbart 0. <br>\n",
    "    \n",
    "Dette forteller oss at singulærvektorene inneholder noen få viktige bilder, mange mindre viktige, men brukbare bilder, og en del bilder som er neglisjerbare. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Oppgave 2c\n",
    "Med vår SVD, tester vi dens trunktering på MNIST-datasettet. <br>\n",
    "Vi ser på fire ulike trunkterte svd, hver med økende grad av d valgte elementer. <br>\n",
    "Med disse dictionaris(ene) med ulike d, ser vi hva vi får når det projekteres på en vektore den er trent på, og en vektor den ikke er trent på.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def manytruncSVD(A, d):\n",
    "    \"\"\"\n",
    "    Gjør et svd med en LISTE av de d viktigste leddene i matrisen, altså flere trunkterte versjoner av vanlig SVD-regning.\n",
    "\n",
    "    Input:\n",
    "    A: Datasett-martise\n",
    "    d: En liste med antall U-kolonner/S-singulærvektorer/V-rader som skal brukes\n",
    "\n",
    "    Output:\n",
    "    W: En liste med dictionaries\n",
    "    (Bytt til manyW?)\n",
    "    S: Singulærvektorene til W. Brukes i 2d\n",
    "    \"\"\"\n",
    "\n",
    "    W = np.array([np.zeros((A.shape[0], A.shape[0]))] * len(d))\n",
    "\n",
    "    maxW = truncSVD(A, max(d))[0]\n",
    "\n",
    "    W[np.argmax(d)][:, :d[np.argmax(d)]] = maxW \n",
    "    d[np.argmax(d)] = 0\n",
    "\n",
    "    while max(d) != 0:\n",
    "        W[np.argmax(d)][:, :d[np.argmax(d)]] = maxW[:, :max(d)]\n",
    "        d[np.argmax(d)] = 0\n",
    "\n",
    "    return W, S\n",
    "\n",
    "def manyorthproj(W, B, antall):\n",
    "\n",
    "    I = [\"text\"] * antall\n",
    "\n",
    "    images = np.zeros((antall, A.shape[0]))\n",
    "\n",
    "    for i in range(antall):\n",
    "        images[i] = (np.transpose(orthproj(W[i], b)))\n",
    "        I[i] = images[i][np.newaxis, :]\n",
    "    return I\n",
    "\n",
    "def fiveplotter(W, B, antall):\n",
    "    \"\"\"I = image\"\"\"\n",
    "\n",
    "    I = manyorthproj(W, B, len(d))\n",
    "    zeros = np.zeros((1, A.shape[0]))\n",
    "    b = np.transpose(B)\n",
    "\n",
    "    totimage = np.transpose(np.concatenate((I[0], I[1], zeros, I[2], I[3], zeros, zeros, zeros, b), axis = 0))\n",
    "\n",
    "    plotimgs(totimage, 3)\n",
    "\n",
    "\"\"\"henter verdier\"\"\"\n",
    "A = train[:,c,:n]\n",
    "d = np.array([16, 32, 64, 128])\n",
    "W = manytruncSVD(A, d)[0]\n",
    "antall = 4\n",
    "\n",
    "\"\"\"første bilde\"\"\"\n",
    "\n",
    "b = train[:,0,:1]\n",
    "fiveplotter(W, b, antall)\n",
    "\"\"\"annen tall\"\"\"\n",
    "\n",
    "b = train[:,1,:1]\n",
    "fiveplotter(W, b, antall)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Med en vektor dictionarien er trent opp med, ser vi at med høyere d, klarer den å projektere den originale 0 inntil sin dictionary bedre og bedre.\n",
    "Det samme skjer visuellt med bildet den ikke er trent på, men her er den alltid mye mer blurry enn den andre vektoren.\n",
    "Det er fordi dette 1-bildet projiserer den som om bildet var en 0, men det er den ikke.\n",
    "Da får vi blur mellom 0 og 1, der 1 viser sterkere jo høyere d vi får, men får masse artifakter rundt eneren.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Oppgave 2d\n",
    "For å sjekke bildenes sanne forskell med dictionaries(ene) finner vi deres distance til dem.\n",
    "Vi bruker frobenius-norm for å finne distansene til disse bildematrisen og dictionaries(ene).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Frobenium Norm Squared = FMS\n",
    "def FMS(A):\n",
    "    \n",
    "    \"\"\"\n",
    "    Regner ut Frobeniumn-normen til en matrise, kvadrert\n",
    "    \n",
    "    Input:\n",
    "    A: en matrise\n",
    "    \n",
    "    Output:\n",
    "    frobenium normen kvadrert\n",
    "    \"\"\"\n",
    "    \n",
    "    return sum(sum(A * A))\n",
    "\n",
    "# Henter verdier\n",
    "b = train[:,0,:1]\n",
    "d = np.arange(1, 784, 20)\n",
    "W, S = manytruncSVD(A, d)\n",
    "I = manyorthproj(W, b, len(d))\n",
    "\n",
    "# Setter opp en liste av distansene fra bildene og dictionarie(sene).\n",
    "matrisedist = np.zeros(len(d))\n",
    "\n",
    "# Itererer gjennom FMS, og printer logaritmisk dictionaries(enes) distanser fra første 0-bilde, med hver 20-ende d\n",
    "for i in range(len(d)):\n",
    "    matrisedist[i] = FMS(b[:,0] - I[i])\n",
    "plt.semilogy(matrisedist, label=\"Distanse fra 0\")\n",
    "\n",
    "# Itererer gjennom FMS, og printer logaritmisj dictionaries(enes) distanser fra første 1-bilde, med hver 20-ende d\n",
    "annettall = train[:,1,:1]\n",
    "for i in range(len(d)):\n",
    "    matrisedist[i] = FMS(annettall[:,0] - I[i])\n",
    "\n",
    "plt.semilogy(matrisedist, label=\"Distanse fra 1\")\n",
    "plt.xlabel(\"Verdi for 'd'\")\n",
    "plt.ylabel(\"Distanse Verdi\")\n",
    "plt.title(\"Sammenlikning av distanse for et trent tall mot ikke trent\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Her ser vi at distansen fra 0-bildet synker mer og mer jo høyere d vi har (Blå linje).\n",
    "Dette gjir mening, siden maskinen har da flere vektorer den kan bruke til å bedre projektere bildet.\n",
    "Vi ser også at den ligner veldig mye på bildets singulærverdier.\n",
    "Dette er fordi grafen av singulærverdiene er også basert på hvor høye d-verdiene er. <br>\n",
    "\n",
    "Man kan si at verdiene til singulærvektorene forteller viktigheten til et spesifikt dictionary, altså hvor mye \"kraft den skal ha\",\n",
    "som betyr hvor mye den skal påvirke projiseringen, og dermed hvor forskjellig den nå er til det reelle bilde, altså avstanden fra b til projektert b. Vi ser også at på et punkt er distansen omtrent lik null, som viser oss at det er et \"maks\" antall d, som større en den vil ikke gi oss forbedringer.\n",
    "\n",
    "\n",
    "Det andre bildet (Oransje), gir samme distanse uansett d, fordi dette bildet er ikke blitt trent opp i dictionarien.\n",
    "Uansett hva maskinen gjør, har den ingen dictionaries som matcher det nye bildet.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Oppgave 2e\n",
    "Nå gjør vi det samme som vi hittil har gjort, men med den ikke-negative måten.\n",
    "Vi plotter deres projeksjoner først, og ser hva vi får av dem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Henter verdier\n",
    "d = 32\n",
    "A = train[:,c,:n]\n",
    "nxn = 4\n",
    "\n",
    "#Henter test-bilder, og dictionaries\n",
    "Ann = A[:,np.random.choice(A.shape[1],nxn**2,replace=False)]\n",
    "Wpluss = A[:,np.random.choice(A.shape[1],d,replace=False)]\n",
    "\n",
    "# Projekterer bildene, og plotter dem\n",
    "proj = nnproj(Wpluss, Ann)[0]\n",
    "plotimgs(proj, nxn)\n",
    "plotimgs(Ann, nxn)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Her ser vi tilfeldig valgte opptrente bilder (Øverst), og tilfeldig valgte test-bilder (Nederst).\n",
    "Vi ser at alle sammen er litt blurry i forhold til bildet med d = 32 på oppgave 2c,\n",
    "siden dictionarisene ikke er sortert fra best til verst, men er heller plukket fram tilfeldig.\n",
    "\n",
    "Vi kan også observere at de tilfeldig valgte opptrente bildene har fanget de 'viktigste egenskapene' bak en nuller, som i 2c"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Oppgave 2f\n",
    "Nå sjekker vi distansene vi får med høyere d, og ulike bilder, med den ikke-negative metoden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gjør flere ikke-negative projiseringer \n",
    "def manynnproj(Wpluss, B, d):\n",
    "\n",
    "    proj = np.array([np.zeros((A.shape[0], 1))] * len(d))\n",
    "\n",
    "    proj[np.argmax(d)]= nnproj(Wpluss, b)[0]\n",
    "    d[np.argmax(d)] = 0\n",
    "\n",
    "\n",
    "    while max(d) != 0:\n",
    "        Wpluss = Wpluss[:,np.random.choice(Wpluss.shape[1],max(d),replace=False)]\n",
    "        proj[np.argmax(d)] = nnproj(Wpluss, b)[0]\n",
    "        d[np.argmax(d)] = 0\n",
    "\n",
    "    return proj\n",
    "\n",
    "#  Genererer 10 tall mellom 1 og 1000, logaritmisk skalert\n",
    "d = np.logspace(1,3,10, dtype = np.int64)\n",
    "\n",
    "A = train[:,c,:n]\n",
    "Wpluss = A[:,np.random.choice(A.shape[1],max(d),replace=False)]\n",
    "\n",
    "b = train[:,0,:1]\n",
    "\n",
    "\n",
    "manyproj = manynnproj(Wpluss, b, d)\n",
    "\n",
    "\n",
    "matrisedist = np.zeros(len(d))\n",
    "\n",
    "\n",
    "for i in range(len(d)):\n",
    "    matrisedist[i] = FMS(b - manyproj[i])\n",
    "\n",
    "\n",
    "plt.semilogy(matrisedist, label=\"Distanse fra 0\")\n",
    "\n",
    "annettall = train[:,1,:1]\n",
    "\n",
    "for i in range(len(d)):\n",
    "    matrisedist[i] = FMS(annettall - manyproj[i])\n",
    "\n",
    "plt.xlabel(\"Verdi for 'd'\")\n",
    "plt.ylabel(\"Distanse Verdi\")\n",
    "plt.semilogy(matrisedist, label=\"Distanse fra 1\")\n",
    "plt.title(\"Sammenlikning av distanse for et trent tall mot ikke trent\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I forhold til plotten fra 2d, ser vi at distansen fra 0-bildet synker først mer og mer jo høyere d vi har (Blå graf).\n",
    "Men så ser vi at den blir ganske tilfelidg ved de største d, og at det ikke er alltid at distansen er lav.\n",
    "Det er fordi H-matrisen som konvergerer ved nnproj er nå så stor at maxiter = 50 er for lite til at den kan skikkelig konvergere.\n",
    "Dette skaper tilfeldighetene, ettersom H vil nå være preget av tilfeldigheter fra randint.\n",
    "\n",
    "Det andre bildet (Oransje graf), gir samme distanse uansett d, fordi dette bildet er ikke blitt trent opp i dictionarien; selv med den ikke-negative metoden."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Oppgave 3a \n",
    "Nå har vi på plass det vi trenger for å starte med å klassifisere bildene.\n",
    "Først lager vi en funksjon som genererer et sett med test-bilder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_test(test, digits = [0,1,2], N = 800):\n",
    "    \n",
    "    \"\"\"\n",
    "    Tilfeldig genererer test sets.\n",
    "    \n",
    "    Input:\n",
    "        test: numpy array. Test data lastet ned fra filen\n",
    "        digits: python lists. Inneholder ønskede heltall\n",
    "        N: Heltall mengde test data for hver klasse\n",
    "    \n",
    "    Output:\n",
    "        test_sub: (784,len(digits)*N) numpy array. Inneholder len(digits)*N bilder\n",
    "        test_labels: (len(digits)*N) numpy array. Inneholder etiketter korresponderende til bildene av test_sub\n",
    "    \"\"\"\n",
    "\n",
    "    assert N <= test.shape[2] , \"N må være mindre enn eller lik det totale mengden av tilgjengelig test data for hver klasse\"\n",
    "\n",
    "    assert len(digits)<= 10, \"Liste av tall kan bare holde opp til 10 tall\"\n",
    "\n",
    "    # Arrays til å lagre test sets og etiketter\n",
    "    test_sub = np.zeros((test.shape[0], len(digits)*N))\n",
    "    test_labels = np.zeros(len(digits)*N)\n",
    "\n",
    "    # Itererer over alle tall-klasser, og lagrer test data og etiketter\n",
    "    for i, digit in enumerate(digits):\n",
    "        test_sub[:, i*N:(i+1)*N] = test[:,digit,:]\n",
    "        test_labels[i*N:(i+1)*N] = digit\n",
    "\n",
    "    # Indekser til å bli shufflet \n",
    "    ids = np.arange(0,len(digits)*N)\n",
    "\n",
    "    # Shufflet indekser\n",
    "    np.random.shuffle(ids)\n",
    "\n",
    "    # Returnerer shufflet data \n",
    "    return test_sub[:,ids], test_labels[ids]\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vi printer ut settet, og sjekker om den er ok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "digits = np.array([0, 1, 2])\n",
    "\n",
    "N = 800\n",
    "\n",
    "A_test, A_labels = generate_test(test, digits = digits, N = 800)\n",
    "print(\"Test data shape: \", A_test.shape) # Bør være (784,2400)\n",
    "print(\"Test labels shape: \", A_labels.shape) # Bør være (2400)\n",
    "print(\"First 16 labels: \", A_labels[:16])\n",
    "plotimgs(A_test, nplot = 4)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Med en test-matrise, bruker vi den til å klassifisere dem via å finne deres distanse fra de ulike dictionary-projeksonene deres.\n",
    "Vi henter først deres data fra én talltype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Henter dictionaries, projeksjoner, og distanser av treningsmatrise A og testmatrise B\n",
    "def datacollection(A, B, d):\n",
    "    \n",
    "    \"\"\"\n",
    "    Henter Dictionary, projeksjon, og distanse av en klasse bilder\n",
    "    \n",
    "    Input:\n",
    "    A: Trenings-bilder\n",
    "    B: Test-bilder\n",
    "    d: Antall U-kolonner/S-singulærvektorer/V-rader som skal brukes\n",
    "    \n",
    "    Output:\n",
    "    Wodict: Ortogonale dictionaries\n",
    "    Wnndict: Ikke-negative dictionaries\n",
    "    Woproj: Ortogonale projeksjoner\n",
    "    Wnnproj: Ikke-negative projeksjoner\n",
    "    Wodist: Ortogonale distanser\n",
    "    Wnndist: Ikke-negative distanser\n",
    "    \"\"\"\n",
    "        \n",
    "    # Henter dictionaries\n",
    "    Wodict = truncSVD(A, d)[0]\n",
    "    Wnndict = A[:,np.random.choice(A.shape[1],d,replace=False)]\n",
    "    \n",
    "    # Regner ut projeksjoner\n",
    "    Woproj = orthproj(Wodict, B)\n",
    "    Wnnproj = nnproj(Wnndict, B)[0]\n",
    "    \n",
    "    # Regner ut distanser\n",
    "    Wodist = ortdist(Wodict, B)\n",
    "    Wnndist = nndist(Wnndict, B)\n",
    "    \n",
    "    # Returnerer data\n",
    "    return Wodict, Wnndict, Woproj, Wnnproj, Wodist, Wnndist\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Så henter vi ut denne informasjonen fra hver talltype, og klassifiserer bildene"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def klassifisering(A, B, c, d):\n",
    "    \"\"\"\n",
    "    Klassifiserer bilder\n",
    "    \n",
    "    Input:\n",
    "    A: Trenings-bilder\n",
    "    B: Test-bilder\n",
    "    c: klassen til bildene\n",
    "    d: Antall U-kolonner/S-singulærvektorer/V-rader som skal brukes\n",
    "    \n",
    "    Output:\n",
    "    classifyOlabels: en loste med predikterte klassifikasjoner av test-bilder, ortogonalt\n",
    "    classifyNlabels: en loste med predikterte klassifikasjoner av test-bilder, ikke-negativt\n",
    "    Odictlist: En liste med ortogonale dictionaries\n",
    "    Ndictlist: En liste med ikke-negative dictionaries\n",
    "    Oprojlist: En liste med ortogonale projeksjoner\n",
    "    Nprojlist: En liste med ikke-negative projeksjoner\n",
    "    Odistlist: En liste med ortogonale distanser\n",
    "    Ndistlist: En liste med ikke-negative distanser\n",
    "    \"\"\"\n",
    "    \n",
    "    # Lager lister for oppbevaring av ulike dictionaries, projeksoner, og distanser, for O = Ortogonale og N = ikke-Negative sett\n",
    "    Odictlist = np.zeros((len(c), len(B[:,0]), d))\n",
    "    Ndictlist = np.zeros((len(c), len(B[:,0]), d))\n",
    "    \n",
    "    Oprojlist = np.zeros((len(c), len(B[:,0]), N*len(c)))\n",
    "    Nprojlist = np.zeros((len(c), len(B[:,0]), N*len(c)))\n",
    "    \n",
    "    Odistlist = np.zeros((len(c), len(B[0])))\n",
    "    Ndistlist = np.zeros((len(c), len(B[0])))\n",
    "    \n",
    "\n",
    "    # Henter data fra hver talltype    \n",
    "    for i in range(len(c)):\n",
    "        Ac = A[:, n*i : n*(i+1)]\n",
    "        Odictlist[i], Ndictlist[i], Oprojlist[i], Nprojlist[i], Odistlist[i], Ndistlist[i] = datacollection(Ac, B, d)\n",
    "    \n",
    "    # Lager lister for klassifisering av bildene    \n",
    "    classifyOlabels = np.zeros(len(B[0]))\n",
    "    classifyNlabels = np.zeros(len(B[0]))\n",
    "    \n",
    "    # Klassifiserer bildene    \n",
    "    for i in range(len(B[0])):\n",
    "        classifyOlabels[i] = c[np.argmin(Odistlist[:,i])]\n",
    "        classifyNlabels[i] = c[np.argmin(Ndistlist[:,i])]\n",
    "\n",
    "    # Returnerer klassifiseringer, dictionaries, projeksoner, og distancer for alle talltyper   \n",
    "    return classifyOlabels, classifyNlabels, Odictlist, Ndictlist, Oprojlist, Nprojlist, Odistlist, Ndistlist\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nå har vi en kode som klassifiserer ethvert bilde med ethvert dictionary."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Oppgave 3b"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vi tester dette med de vanlige projeksjonene, test-bildene, tre talltyper {$0,1,2$} og med d = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Henter verdier\n",
    "c = digits\n",
    "\n",
    "A = np.zeros((len(train[:,0,0]), n*len(c)))\n",
    "              \n",
    "for i in range(len(c)):\n",
    "    A[:, n*i : n*(i+1)] = train[:,c[i],:n]\n",
    "\n",
    "B = A_test\n",
    "d = 32\n",
    "\n",
    "\n",
    "# Henter etiketter og datasett-prediksjoner fra maskinen\n",
    "truelabel = A_labels\n",
    "predictions = klassifisering(A, B, c, d)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Det vil være et rot å se gjennom alle klassifikasjonene.\n",
    "Derfor setter vi opp en metode for å finne ut hvor god klassifiseringen er\n",
    "Vi bruker her accuracy og recall: Acc = riktig / total-mengde, og Rec = riktig-av-talltype / total-mengde-av-talltype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finner accuracy og recall\n",
    "def recallandacc(c, truelabel, predictions):\n",
    "    \"\"\"\n",
    "    Regner ut accuracy og recall for hver talltype\n",
    "    \n",
    "    Input:\n",
    "    c: klassen til bildene\n",
    "    truelabel: de sanne etikettene til hver bilde\n",
    "    predictions: prediksjoner og data fra A, B, c, og d.\n",
    "    \n",
    "    Output:\n",
    "    Orecall: En liste med recall for ortogonale test-bidler\n",
    "    Nrecall: En liste med recall for ikke-negative test-bidler\n",
    "    Oacc: accuracy for ortogonale test-bidler\n",
    "    Nacc: accuracy for ikke-negative test-bidler\n",
    "    \"\"\"\n",
    "\n",
    "    # recall\n",
    "    Orecall = np.zeros(len(c))\n",
    "    Nrecall = np.zeros(len(c))\n",
    "\n",
    "    # Regner ut recall fra begge metodene    \n",
    "    for i in range(len(c)):\n",
    "        OErI = truelabel == c[i]\n",
    "        OmenerErI = predictions[0][OErI]\n",
    "        OsammenlignErI = OmenerErI == c[i]\n",
    "        Oantallriktige = OmenerErI[OsammenlignErI]\n",
    "        Orecall[i] = len(Oantallriktige) / len(OmenerErI)\n",
    "        \n",
    "        NErI = truelabel == c[i]\n",
    "        NmenerErI = predictions[1][NErI]\n",
    "        NsammenlignErI = NmenerErI == c[i]\n",
    "        Nantallriktige = NmenerErI[NsammenlignErI]\n",
    "        Nrecall[i] = len(Nantallriktige) / len(NmenerErI)\n",
    "\n",
    "    # Regner ut accuracy        \n",
    "    Oacc = sum(Orecall) / len(c)\n",
    "    Nacc = sum(Nrecall) / len(c)\n",
    "\n",
    "    # Returnerer accuracy of recall for både O og N    \n",
    "    return Orecall, Nrecall, Oacc, Nacc\n",
    "\n",
    "# Printer deres accuracy of recall\n",
    "print(recallandacc(c, truelabel, predictions))\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Her ser vi accuracyen av recallen fra hver metode, fra hver talltype.\n",
    "De er på omtrent 99 til 98% området.\n",
    "Vi ser at den ortogonale metoden funker litt bedre enn den ikke-negative.\n",
    "Det kan være fordi den ikke-negative ikke spenner ut hele rommet, men heller bare en del av det.\n",
    "Dette kan gjøre at distansamplingen blir annerledes enn den ortogonale metoden, som er mer nøyaktig, men tregere for å gjøre en SVD. <br>\n",
    "Vi ser også at tallet 2 er vanskeligere å klassifisere enn 0 og 1.\n",
    "Dette er trolig fordi 0 og 1 har enkle former mens 2 er en litt mer avansert ett."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Oppgave 3c\n",
    "Vi ser litt på forskjellen på hva klassifiseringen kan gjøre.\n",
    "Vi printer først et bilde som har lavest projeksjonsdistanse fra tallet 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vi plotter bilder fra tallet 0.\n",
    "Class = 0\n",
    "\n",
    "# Finner minste avstand fra hver metode.\n",
    "ODist = np.argmin(predictions[6][Class])\n",
    "NDist = np.argmin(predictions[7][Class])\n",
    "\n",
    "# Henter bildet med den minste distansen, og dens projsering, avhengig av hvilken metode ga minst distanse. Skriver også om det er O eller N\n",
    "if predictions[6][Class][ODist] < predictions[7][Class][NDist]:\n",
    "    \n",
    "    b = B[:,ODist]\n",
    "    proj = predictions[4][Class][:,ODist]\n",
    "    Type = 0    \n",
    "else:\n",
    "    b = B[:,NDist]\n",
    "    proj = predictions[5][Class][:,NDist]\n",
    "    Type = 1\n",
    "\n",
    "def comparepic(b, proj):\n",
    "    \"\"\"\n",
    "    Plotter en bilde og dens projeksjon sammen\n",
    "    \n",
    "    Input:\n",
    "    b: bildet\n",
    "    proj: projeksonen til bildet\n",
    "    \n",
    "    Output:\n",
    "    En plott av bildet og dens projeksjon sammen\n",
    "    \"\"\"\n",
    "\n",
    "    # Setter dem opp til plotting    \n",
    "    b = b[np.newaxis, :]\n",
    "    proj = proj[np.newaxis, :]\n",
    "\n",
    "    # Henter blanke bilder, setter bildene sammen, og plotter dem   \n",
    "    zeros = np.zeros((1, b.shape[1]))\n",
    "    totimage = np.transpose(np.concatenate((proj, zeros, zeros, b), axis = 0))\n",
    "    plotimgs(totimage, 2)\n",
    "\n",
    "# Plotter bildet og dens projeksjon sammen\n",
    "comparepic(b, proj)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bilde viser oss at projeksjonen er nesten identisk med det originale bildet.\n",
    "Den har noe artifakter rundt seg, men de sterke punktene er alle omtrent nøyaktig projisert fra der 0-bildet faktisk er.\n",
    "Dette gir en veldig liten distanse til å klassifisere den som et 0."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Oppgave 3d"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nå ser vi på motsatt tilfelle.\n",
    "Vi analyserer et bilde som ble feilklassifisert."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Henter klassifiseringer avhengig av om det er O eller N\n",
    "predict = predictions[0 + Type]\n",
    "\n",
    "# Finner indekser til misklassifiserte bilder\n",
    "indexfind = np.arange(len(B[0]))\n",
    "\n",
    "foundindex = indexfind[(truelabel == Class) & (predict != truelabel)]\n",
    "\n",
    "# Henter det første feilklassifiserte bildet\n",
    "try:\n",
    "    index = foundindex[0]\n",
    "except:\n",
    "    index = foundindex\n",
    "\n",
    "# Setter opp bildet og dens projisering\n",
    "b = B[:,index]\n",
    "proj = predictions[4 + Type][Class][:,index]\n",
    "\n",
    "# Plotter dem sammen\n",
    "comparepic(b, proj)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Her har vi et mye mer fuzzy bilde sammenliknet med 3c.\n",
    "Dette gjør at det er vanskeligere å klassifisere den som et riktig tall.\n",
    "Ikke nok med det, ser 0-tallet, avhengig av hvilken bilde som ble valgt, litt ut som tallet 1 eller 2 også.\n",
    "Dette viser oss at noen bilder er lette å klassifisere, mens andre er mye vanskeligere."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Oppgave 3e"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nå gjør vi det sammme som på 3b, men med en ekstra talltype."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Henter verdier med en ekstra talltype\n",
    "c = np.array([0, 1, 2, 3])\n",
    "\n",
    "A = np.zeros((len(train[:,0,0]), n*len(c)))\n",
    "              \n",
    "for i in range(len(c)):\n",
    "    A[:, n*i : n*(i+1)] = train[:,c[i],:n]\n",
    "\n",
    "    \n",
    "A_test, A_labels = generate_test(test, digits = c, N = 800)\n",
    "\n",
    "B = A_test\n",
    "d = 32\n",
    "\n",
    "# Henter etiketter og datasett-prediksjoner fra maskinen\n",
    "truelabel = A_labels\n",
    "predictions = klassifisering(A, B, c, d)\n",
    "\n",
    "# Printer de nye accuracy og recall\n",
    "\n",
    "print(recallandacc(c, truelabel, predictions))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Første array er den ortogonale, andre er for den ikke negative. Tallene er i samme rekkefølge som i arrayene. Til slutt kommer accuracy i samme rekkefølge som array-ene.\n",
    "\n",
    "Her ser vi en del forskjeller fra 3b.\n",
    "Recall og Accuracy er for de lette tallene (0,1) litt lavere, mens de er mye lavere for de mer avanserte.\n",
    "Dette kan være fordi flere typer dictionaries gjør at det er vanskeligere å klassifisere én type tall."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Oppgave 3f"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Til slutt gjør vi det samme som forrige oppgave, men med ulike d."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Henter verdier \n",
    "c = np.array([0, 1, 2, 3])\n",
    "\n",
    "A = np.zeros((len(train[:,0,0]), n*len(c)))\n",
    "              \n",
    "for i in range(len(c)):\n",
    "    A[:, n*i : n*(i+1)] = train[:,c[i],:n]\n",
    "\n",
    "    \n",
    "A_test, A_labels = generate_test(test, digits = c, N = 800)\n",
    "\n",
    "B = A_test\n",
    "truelabel = A_labels\n",
    "\n",
    "exp = np.arange(10)\n",
    "d = 2**exp\n",
    "\n",
    "# Lager lister for overall accuracy\n",
    "overallacc1 = np.zeros(len(d))\n",
    "overallacc2 = np.zeros(len(d))\n",
    "\n",
    "# Regner accuracy og recall fra bildene med ulike d\n",
    "dummy = 0\n",
    "for i in d:\n",
    "    predictions = klassifisering(A, B, c, i)\n",
    "    xx, yy, overallacc1[dummy], overallacc2[dummy] = recallandacc(c,truelabel, predictions)\n",
    "    print(xx, yy, overallacc1[dummy], overallacc2[dummy])\n",
    "    dummy +=1\n",
    "\n",
    "# Plotter dens accuracy og recall\n",
    "plt.plot(d,overallacc2,label=\"Ortogonal Accuracy\")\n",
    "plt.plot(d,overallacc1, label=\"Ikke-negativ Accuracy\")\n",
    "plt.ylabel(\"% Riktig\")\n",
    "plt.xlabel(\"Verdi for 'd'\")\n",
    "plt.title(\"Overall accuracy mot verdi for 'd' for Ortogonal og Ikke-negativ metodene\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotten viser oss accuracyen for de to ulike metodene\n",
    "\n",
    "Vi ser at SVD-metoden gir mer og mer nøyaktgie accuracy, selv om den allerede har meget stor accuracy; altså at den beste d er den høyeste d = 500.\n",
    "Vi ser også at ENMF-metoden gir gode svar ved relative lave d, men at det stadig går lengre ned ettersom den får høyere d; den høyeste accuracy for den er d = \n",
    "Dette er fordi SVD gir et mer og mer nøyaktig dictionary, som vi testet i 2d.\n",
    "\n",
    "For EMNF, ser vi at den når et toppunpt får den dipper krafitg ned.\n",
    "Dette kan forklares ved 2f, ved at H tar mye lengre tid på å konvergere, som gjør at den skaper mer og mer unøyaktigheter ved et kritisk d"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Oppgave 3g\n",
    "Da har vi endelig laget et fullferdig klassifiseringsmaskin, ved denne prosessen av dictionary learning.\n",
    "\n",
    "Vi gikk gjennom matematiske prosesser for å forstå hvordan vi kan utføre det,. <br>\n",
    "vi gikk gjennom data fra MNIST til å utføre dictionary learning,\n",
    "vi så på hvordan den projekterer nye bilder til dictionary-en (ordboka) den har lært,\n",
    "og vi så på hvordan maskinen klassifiserer mange ulike tallbilder i dybde. <br> <br>\n",
    "\n",
    "Slike maskiner brukes til mye annet ting enn å bare klassifisere tall,.\n",
    "Den kan klassifisere om det står en person foran en selvkjørende bil, hvilken feed en bruker skal få, on en mail er spam, om en pasient har en høy-risiko for keft, og mye mer\n",
    "Slike maskiner er i en prosees av å revolusjonere verden, slik vi kjenner den, eller gjør det nå allerede."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3633f438634194677d5a56fa82856b886ad79a013c3710805264d16212529561"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
