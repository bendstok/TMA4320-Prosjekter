{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nT E K S T MARKDOWN!!!!\\n# Dictionary learning\\n\\nI denne rapporten ser vi på det som kalles for \"Dictionary learning\", og hvordan en maskin kan gjenkjenne fra hverandre to bilder av ulike tall, 0, og 1. <br>\\nVi ser først gjennom noen matematiske prosesser for å forstå hvordan vi kan utføre dictionary learning. <br>\\nSå bruker vi data fra MNIST til å utføre dictionary learning, og ser hvordan den projekterer nye bilder til dictionary-en (ordboka) den har lært. <br>\\nTil slutt ser vi på hvordan maskinen klassifiserer mange ulike tallbilder i dybde. <br> <br>\\n\\nFørst undersøker vi matematikken. Matrisene A representerer sett med \"bilder\", der hver kolonne skal representere et bilde. <br>\\nDisse bildene kan brukes til å trene opp datamaskinen, og til å få dem i maskinens dictionary. <br>\\nKolonnevektorene b representerer nye bilder. <br>\\nDisse brukes til å teste hvordan maskinen ser på nye bilder i forhold til dictionary-en sin, altså hvordan den klassifiserer de nye bildene.\\nT E K S T MARKDOWN!!!!\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"punktum ta det lol.\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "T E K S T MARKDOWN!!!!\n",
    "# Dictionary learning\n",
    "\n",
    "I denne rapporten ser vi på det som kalles for \"Dictionary learning\", og hvordan en maskin kan gjenkjenne fra hverandre to bilder av ulike tall, 0, og 1. <br>\n",
    "Vi ser først gjennom noen matematiske prosesser for å forstå hvordan vi kan utføre dictionary learning. <br>\n",
    "Så bruker vi data fra MNIST til å utføre dictionary learning, og ser hvordan den projekterer nye bilder til dictionary-en (ordboka) den har lært. <br>\n",
    "Til slutt ser vi på hvordan maskinen klassifiserer mange ulike tallbilder i dybde. <br> <br>\n",
    "\n",
    "Først undersøker vi matematikken. Matrisene A representerer sett med \"bilder\", der hver kolonne skal representere et bilde. <br>\n",
    "Disse bildene kan brukes til å trene opp datamaskinen, og til å få dem i maskinens dictionary. <br>\n",
    "Kolonnevektorene b representerer nye bilder. <br>\n",
    "Disse brukes til å teste hvordan maskinen ser på nye bilder i forhold til dictionary-en sin, altså hvordan den klassifiserer de nye bildene.\n",
    "T E K S T MARKDOWN!!!!\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importerer biblioteker\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"\"\"\n",
    "T E K S T MARKDOWN!!!!\n",
    "### Oppgave 1a\n",
    "Først skriver vi ned vektorene, som vi skal bruke i denne delen av oppgaven\n",
    "T E K S T MARKDOWN!!!!\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Skriver inn test-datasetter A1 og A2, hver med kolonner som datapunkter\n",
    "A1 = np.array([[1000, 1], [0, 1], [0, 0]])\n",
    "A2 = np.array([[1, 0, 0], [1, 0, 0], [0, 0, 1]])\n",
    "\n",
    "#Skriver inn test-vektorer, og setter det sammen til en matrise\n",
    "b1 = np.array([[2], [1], [0]])\n",
    "b2 = np.array([[0], [0], [1]])\n",
    "b3 = np.array([[0], [1], [0]])\n",
    "B = np.concatenate((b1, b2, b3), axis=1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"\"\"\n",
    "T E K S T MARKDOWN!!!!\n",
    "Det første vi gjør, er å åpne opp A1 ved å regne ut dens SVD: A = U @ S @ Vt. U er dens dictionary W, mens S @ Vt er dens vektmatrise H.\n",
    "Vi undersøker dens egenskaper\n",
    "T E K S T MARKDOWN!!!!\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "U =\n",
      "[[ 1.e+00 -1.e-06]\n",
      " [ 1.e-06  1.e+00]\n",
      " [ 0.e+00  0.e+00]] \n",
      "\n",
      "Formen på U: (3, 2)\n",
      "\n",
      "S (egenvektorene) =\n",
      "[1.0000005e+03 9.9999950e-01] \n",
      "\n",
      "Formen på S: (2,)\n",
      "\n",
      "Vt =\n",
      "[[ 0.9999995  0.001    ]\n",
      " [-0.001      0.9999995]] \n",
      "\n",
      "Formen på Vt: (2, 2)\n",
      "\n",
      "A1 rekonstruert =\n",
      "[[ 1.00000000e+03  1.00000000e+00]\n",
      " [-2.18499053e-19  1.00000000e+00]\n",
      " [ 0.00000000e+00  0.00000000e+00]]\n"
     ]
    }
   ],
   "source": [
    "# Regner ut SVD\n",
    "U, S, Vt = np.linalg.svd(A1, full_matrices = False)\n",
    "\n",
    "# Printer ut svd-matrisene\n",
    "print(f\"U =\\n{U} \\n\")\n",
    "print(f\"Formen på U: {U.shape}\\n\")\n",
    "print(f\"S (egenvektorene) =\\n{S} \\n\")\n",
    "print(f\"Formen på S: {S.shape}\\n\")\n",
    "print(f\"Vt =\\n{Vt} \\n\")\n",
    "print(f\"Formen på Vt: {Vt.shape}\\n\")\n",
    "\n",
    "# Gjør S sine egenvektorer til en matrise. (FS = Full S)\n",
    "FS = np.diag(S)\n",
    "\n",
    "# Rekonstruerer, og printer\n",
    "A = U @ FS @ Vt\n",
    "print(f\"A1 rekonstruert =\\n{A}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"\"\"\n",
    "T E K S T MARKDOWN!!!!\n",
    "Her ser vi at U er på formen (3, 2).\n",
    "Vanligvis skal den være (3, 3). det viser oss at den siste kolonnen var bare fyllt med 0, og er dermed ubrukelig for oss. <br>\n",
    "Dette ser vi er tilfelle, fordi ved å rekonstruere A1, ser vi at vi får samme resultat. <br>\n",
    "Vi finner vi ut hvor viktig de to andre kolonnene er til å rekonstruere A.\n",
    "T E K S T MARKDOWN!!!!\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A1 rekonstruert, uten U[:,1] =\n",
      "[[1.000000e+03 1.000001e+00]\n",
      " [1.000000e-03 1.000001e-06]\n",
      " [0.000000e+00 0.000000e+00]]\n",
      "\n",
      "A1 rekonstruert, uten U[:,0] =\n",
      "[[ 1.00000e-09 -9.99999e-07]\n",
      " [-1.00000e-03  9.99999e-01]\n",
      " [ 0.00000e+00  0.00000e+00]]\n",
      "Første vekk gir en matrise som ikke på noen måte har de samme verdiene der verdiene ikke er 0.\n",
      "Det betyr at denne første kolonnen er viktigst for å rekonstruere matrisen\n"
     ]
    }
   ],
   "source": [
    "# Regner ut SVD\n",
    "U, S, Vt = np.linalg.svd(A1, full_matrices = False)\n",
    "\n",
    "# Fjerner kolonne 2\n",
    "U[:,1] = 0\n",
    "\n",
    "# Rekonstruerer, og printer\n",
    "A = U @ FS @ Vt\n",
    "print(f\"A1 rekonstruert, uten U[:,1] =\\n{A}\\n\")\n",
    "\n",
    "\n",
    "\n",
    "# Henter svd\n",
    "U, S, Vt = np.linalg.svd(A1, full_matrices = False)\n",
    "\n",
    "# Fjerner kolonne 2\n",
    "U[:,0] = 0\n",
    "\n",
    "# Rekonstruerer, og printer\n",
    "A = U @ FS @ Vt\n",
    "print(f\"A1 rekonstruert, uten U[:,0] =\\n{A}\")\n",
    "print(\"Første vekk gir en matrise som ikke på noen måte har de samme verdiene der verdiene ikke er 0.\")\n",
    "print(\"Det betyr at denne første kolonnen er viktigst for å rekonstruere matrisen\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"\"\"\n",
    "T E K S T MARKDOWN!!!!\n",
    "Vi ser at ved å fjerne kolonne 2, får vi omtrent samme svar, bortsett fra indeks A[1][1], som er nå 10^-6, og ikke 1. <br>\n",
    "Med første kolonne vekk istedenfor, får vi en matrise som ikke på noen måte har de samme verdiene der verdiene ikke er 0. <br>\n",
    "Det viser oss at den første kolonnen er viktigst for å rekonstruere matrisen. <br>\n",
    "Det er fordi np.linalg.svd sorterer kolonnene fra mest viktig til minst viktig.\n",
    "T E K S T MARKDOWN!!!!\n",
    "\"\"\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"\"\"\n",
    "T E K S T MARKDOWN!!!!\n",
    "### Oppgave 1b\n",
    "Nå sjekker vi A2, om hva redusering av dens U-kolonner vil gjøre med rekonstrueringen\n",
    "T E K S T MARKDOWN!!!!\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "U =\n",
      "[[-0.70710678  0.         -0.70710678]\n",
      " [-0.70710678  0.          0.70710678]\n",
      " [ 0.          1.          0.        ]] \n",
      "\n",
      "Formen på U: (3, 3)\n",
      "\n",
      "S (egenvektorene) =\n",
      "[1.41421356 1.         0.        ] \n",
      "\n",
      "Formen på S: (3,)\n",
      "\n",
      "Vt =\n",
      "[[-1. -0. -0.]\n",
      " [ 0.  0.  1.]\n",
      " [ 0.  1.  0.]] \n",
      "\n",
      "Formen på Vt: (3, 3)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Henter svd\n",
    "U, S, Vt = np.linalg.svd(A2, full_matrices = False)\n",
    "\n",
    "# Printer ut svd-matrisene\n",
    "print(f\"U =\\n{U} \\n\")\n",
    "print(f\"Formen på U: {U.shape}\\n\")\n",
    "print(f\"S (egenvektorene) =\\n{S} \\n\")\n",
    "print(f\"Formen på S: {S.shape}\\n\")\n",
    "print(f\"Vt =\\n{Vt} \\n\")\n",
    "print(f\"Formen på Vt: {Vt.shape}\\n\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"\"\"\n",
    "T E K S T MARKDOWN!!!!\n",
    "Her ser vi at S har bare 0 ved dens tredje kolonne.<br>\n",
    "Det vi gi FS @ Vt som har sin tredge rad fylt med bare 0. <br>\n",
    "Det vil gjøre den tredje U-kolonnen ubrukelig. <br>\n",
    "Dermed kan vi fjerne denne U-kolonnen, og de korresponderende delene ved S, og Vt, og likevel få den samme matrisen.\n",
    "T E K S T MARKDOWN!!!!\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A2 rekonstruert, uten U[:,2] =\n",
      "[[1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "# Fjerner kolonne 3\n",
    "U[:,2] = 0\n",
    "\n",
    "# Gjør diagonalvektoren til en matrise\n",
    "FS = np.diag(S)\n",
    "\n",
    "# Rekonstruerer, og printer\n",
    "A = U @ FS @ Vt\n",
    "print(f\"A2 rekonstruert, uten U[:,2] =\\n{A}\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"\"\"\n",
    "T E K S T MARKDOWN!!!!\n",
    "Denne er nøyaktig den samme som den originale A2, som bekrefter våre tanker. <br>\n",
    "\n",
    "Vi ser at slik redusering kan spare oss plass og tid om vi ønsker full rekonstruering, eller rask og nesten perfect rekonstruering.(Små singulærverdier spiller mindre rolle i rekonstrueringen av den original matrisen) <br>\n",
    "Vi skriver en funksjon til å gjøre dette.\n",
    "T E K S T MARKDOWN!!!!\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def truncSVD(A, d):\n",
    "    \n",
    "    \"\"\"\n",
    "    Gjør et SVD med de d viktigste leddene i matrisen, altså et trunktert versjon av vanlig SVD-regning,\n",
    "    \n",
    "    Input:\n",
    "    A: Datasett-martise\n",
    "    d: Antall U-kolonner/S-singulærvektorer/V-rader som skal brukes\n",
    "    \n",
    "    Output:\n",
    "    W: Dictionaries\n",
    "    H: Vekt på dictionariesene\n",
    "    \"\"\"\n",
    "    \n",
    "    # Regner ut full SVD\n",
    "    U, S, Vt = np.linalg.svd(A, full_matrices = False)\n",
    "\n",
    "    # Velger de første d relevante vektorer og verdier\n",
    "    U = U[:, :d]\n",
    "    S = S[:d]\n",
    "    Vt = Vt[:d]\n",
    "    \n",
    "    # Gjør diagonalvektoren til en matrise\n",
    "    FS = np.diag(S)\n",
    "    \n",
    "    # Setter inn dictionary og vekt, og returnerer\n",
    "    W = U\n",
    "    H = FS @ Vt\n",
    "    return W, H, S, FS, Vt"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"\"\"\n",
    "T E K S T MARKDOWN!!!!\n",
    "### Oppgave 1c\n",
    "Nå ønsker vi å projektere test-datasettene til de ortogonale dictionaries. <br>\n",
    "Slik kan maskinen dra inn nye datasett til sine dictionaries. <br>\n",
    "Vi tester så dens projeksjon med test-matrisen B på den.\n",
    "T E K S T MARKDOWN!!!!\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Projeksjon av B på W1 =\n",
      "[[2.00000000e+00 0.00000000e+00 8.32531736e-23]\n",
      " [1.00000000e+00 0.00000000e+00 1.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00]]\n",
      "\n",
      "Projeksjon av B på W2 =\n",
      "[[ 2.00000000e+00  0.00000000e+00 -1.33393446e-16]\n",
      " [ 1.00000000e+00  0.00000000e+00  1.00000000e+00]\n",
      " [ 0.00000000e+00  1.00000000e+00  0.00000000e+00]]\n"
     ]
    }
   ],
   "source": [
    "def orthproj(W, B):\n",
    "    \n",
    "    \"\"\"\n",
    "    Tar inn et dictionary med ortogonale kolonner W og et sett med kolonner B og prosjekterer B på W.\n",
    "    \n",
    "    Input:\n",
    "    W: Dictionary med ortogonale kolonner\n",
    "    B: Datasett-matrise, representerer treningsbilder eller testbilder\n",
    "    \n",
    "    Output:\n",
    "    orthproj: En projektert versjon av B på W\n",
    "    \"\"\"\n",
    "    \n",
    "    #Transponerer W\n",
    "    Wt = np.transpose(W)\n",
    "    \n",
    "    #Projekterer B på W, og returnerer\n",
    "    orthproj = W @ Wt @ B\n",
    "    return orthproj\n",
    "\n",
    "\n",
    "# Henter W1, og printer projeksjonen for B på W1\n",
    "W1 = truncSVD(A1, 3)[0]\n",
    "print(f\"Projeksjon av B på W1 =\\n{orthproj(W1, B)}\\n\")\n",
    "\n",
    "# Henter W2, og printer projeksjonen for B på W1\n",
    "W2 = truncSVD(A2, 3)[0]\n",
    "print(f\"Projeksjon av B på W2 =\\n{orthproj(W2, B)}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"\"\"\n",
    "T E K S T MARKDOWN!!!!\n",
    "Disse verdiene viser oss projeksjonen av B på W1 og W2. <br>\n",
    "\n",
    "Nå finner vi deres distanse; distansen fra datasett-matrisene til våre dictionaries. <br>\n",
    "Distansen brukes til å se hvor nerme matrisene matcher dictionariesene. <br>\n",
    "Vi tester så dens distance med test-matrisen B.\n",
    "T E K S T MARKDOWN!!!!\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distansen fra B til W1 =\n",
      "[2.48253415e-16 1.00000000e+00 1.11022302e-16]\n",
      "\n",
      "Distansen fra B til W2 =\n",
      "[1.19574679e-15 0.00000000e+00 2.59032079e-16]\n"
     ]
    }
   ],
   "source": [
    "def ortdist(W, B):\n",
    "    \n",
    "    \"\"\"\n",
    "    Regner ut kolonnevis avstand fra matrise B til dictionary W.\n",
    "    \n",
    "    Input:\n",
    "    W: Dictionary med ortogonale kolonner\n",
    "    B: Datasett-matrise, representerer treningsbilder eller testbilder\n",
    "    \n",
    "    Output:\n",
    "    dist: Distanse fra A til W.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Lager en distansevektor, og setter dem 0. Henter så projeksjonen fra B til W\n",
    "    dist = np.zeros(len(B[0]))\n",
    "    proj = orthproj(W, B)\n",
    "    \n",
    "    #Regner ut distansene til hvert kolonne, og returnerer deres avstand\n",
    "    for i in range(len(dist)):\n",
    "        dist[i] = np.linalg.norm(B[:,i] - proj[:,i])\n",
    "    return dist\n",
    "\n",
    "# Printer projeksjonen for B på W1 og W2\n",
    "print(f\"Distansen fra B til W1 =\\n{ortdist(W1, B)}\\n\")\n",
    "print(f\"Distansen fra B til W2 =\\n{ortdist(W2, B)}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"\"\"\n",
    "T E K S T MARKDOWN!!!!\n",
    "Her ser vi at distansen fra B til W1, kolonnevis, er [0, 1, 0]. <br>\n",
    "Dette viser oss at b1  og b2 er inni W1, mens b2 er utenfor W1. <br>\n",
    "Dette er riktig svar ifølge oppgaveskjemaet vi følger. <br>\n",
    "For W2, ser vi at alle kolonnene i B er inni W2.\n",
    "T E K S T MARKDOWN!!!!\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "T E K S T MARKDOWN!!!!\n",
    "### Oppgave 1d\n",
    "Det kan ta lang tid å trene opp en maskin pga. at en SVD kan ta lang tid å renge ut. <br>\n",
    "Derfor gjør vi også en ikke-negativ fremgang til projeksjon og distansemåling. <br>\n",
    "Vi lager projeksjonsfunksjonen først.\n",
    "T E K S T MARKDOWN!!!!\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Projeksjonen av B på A1, ikke-negativt, =\n",
      "[[2.00029247 0.         0.5       ]\n",
      " [0.99941454 0.         0.5       ]\n",
      " [0.         0.         0.        ]]\n",
      "\n",
      "Vektene til A1, ikke-negativt, =\n",
      "[[0.00100075 0.         0.        ]\n",
      " [0.99950131 0.         0.5       ]]\n",
      "\n",
      "Projeksjonen av B på A2, ikke-negativt, =\n",
      "[[1.5 0.  0.5]\n",
      " [1.5 0.  0.5]\n",
      " [0.  1.  0. ]]\n",
      "\n",
      "Vektene til A2, ikke-negativt, =\n",
      "[[1.5 0.  0.5]\n",
      " [0.  0.  0. ]\n",
      " [0.  1.  0. ]]\n"
     ]
    }
   ],
   "source": [
    "def nnproj(W, B, maxiter=50, safeDiv=10e-10):\n",
    "    \n",
    "    \"\"\"\n",
    "    Tar inn et ikke-negativ dictionary W og matrise A og returnerer den ikke negative projeksjonen av B på W.\n",
    "    \n",
    "    Input:\n",
    "    W: Ikke-negativ dictionary\n",
    "    B: Ikke-negativ datasett-matrise, representerer treningsbilder eller testbilder\n",
    "    maxiter: Antall iterasjoner brukt for å regne ut den ikke-negative vekt-matrisen H\n",
    "    safeDiv: Konstant ledd i divisor for å unngå null-divisjon\n",
    "    \n",
    "    Output:\n",
    "    proj: Den ikke-negative projeksjonen av B på W.\n",
    "    \"\"\"\n",
    "    \n",
    "    #Velger tilfeldlige verdier på H (vekt-matrisen) med verdier fra 0 til 1. Brukes til konvergens til å få den ekte H-matrisen = Wt @ B\n",
    "    H = np.random.uniform(0, 1, [len(W[0,:]), len(B[0])])\n",
    "    \n",
    "    #Transponerer W, og henter inn hjelpeverdiene WtB og WtW\n",
    "    Wt = np.transpose(W)\n",
    "    WtB = Wt@B\n",
    "    WtW = Wt@W\n",
    "    \n",
    "    # Itererer maxiter ganger for å konvergere H til den ekte H-matrisen.\n",
    "    for k in range(maxiter):\n",
    "        H = H*WtB/(WtW@H+safeDiv)\n",
    "    \n",
    "    #projekterer B på W, og returnerer projeksonen\n",
    "    proj = W@H\n",
    "    return proj, H\n",
    "\n",
    "# Printer projeksjonene fra B på A1 og A2, og A-enes vekter:\n",
    "print(f\"Projeksjonen av B på A1, ikke-negativt, =\\n{nnproj(A1, B)[0]}\\n\")\n",
    "print(f\"Vektene til A1, ikke-negativt, =\\n{nnproj(A1, B)[1]}\\n\")\n",
    "print(f\"Projeksjonen av B på A2, ikke-negativt, =\\n{nnproj(A2, B)[0]}\\n\")\n",
    "print(f\"Vektene til A2, ikke-negativt, =\\n{nnproj(A2, B)[1]}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"\"\"\n",
    "T E K S T MARKDOWN!!!!\n",
    "Her ser vi projeksjonene, og vektene. Senere vil vi se at disse gir de riktige verdiene, og viser dermed at denne algoritmen funker. <br>\n",
    "Nå ser vi på distansen fra B til A.\n",
    "T E K S T MARKDOWN!!!!\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distansen fra B til A1, ikke-negativt, =\n",
      "[0.00170677 1.         0.70710678]\n",
      "\n",
      "Distansen fra B til A2, ikke-negativt, =\n",
      "[7.07106781e-01 9.99999972e-10 7.07106781e-01]\n"
     ]
    }
   ],
   "source": [
    "def nndist(W, B):\n",
    "    \n",
    "    \"\"\"\n",
    "    Regner ut kolonnevis avstand fra ikke-negative matrise B til ikke-negativ dictionary W.\n",
    "    \n",
    "    Input:\n",
    "    W: Ikke-negativ dictionary\n",
    "    B: Ikke-negativ datasett-matrise, representerer treningsbilder eller testbilder\n",
    "    \n",
    "    Output:\n",
    "    dist: Distanse fra B til W.\n",
    "    \"\"\"\n",
    "    # Lager en distansevektor, og setter dem 0. Henter så projeksjonen fra B til W\n",
    "    dist = np.zeros(len(B[0]))\n",
    "    proj = nnproj(W, B)[0]\n",
    "    \n",
    "    #Regner ut distansene til hvert kolonne, og returnerer deres avstand\n",
    "    for i in range(len(dist)):\n",
    "        dist[i] = np.linalg.norm(B[:,i] - proj[:,i])\n",
    "    return dist\n",
    "\n",
    "\"\"\"Tester de forskjellige distanse funksjonene\"\"\"\n",
    "print(f\"Distansen fra B til A1, ikke-negativt, =\\n{nndist(A1, B)}\\n\")\n",
    "print(f\"Distansen fra B til A2, ikke-negativt, =\\n{nndist(A2, B)}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"\"\"\n",
    "T E K S T MARKDOWN!!!!\n",
    "Merk at vi her har distansen A til B, og ikke W til B. <br>\n",
    "Her ser vi at distansen fra B til A1, kolonnevis, er [0, 1, 1/Sq(2)]. <br>\n",
    "Dette viser oss at b1 er inni A1, mens b2 og b3 er utenfor A1. <br>\n",
    "Vi ser her at b3 er innenfor spennet av SVD A1, men ikke i kjeglen av den ikke-negative A1. <br>\n",
    "Dette er riktig svar ifølge oppgaveskjemaet vi følger. <br>\n",
    "For A2, ser vi neglisjerbart de samme verdiene, som også er forskjellig fra den vanlige SVD A2.\n",
    "T E K S T MARKDOWN!!!!\n",
    "\"\"\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"\"\"\n",
    "T E K S T MARKDOWN!!!!\n",
    "### Oppgave 2a\n",
    "Nå som vi har matematikken nede og testet, begynner vi med MNIST dataset. <br>\n",
    "Vi laster det ned, og printer ut de 16 første 0-ene.\n",
    "T E K S T MARKDOWN!!!!\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not find dir_path. If using jupyter notebook, ignore\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/train.npy'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_14624/1297744843.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m     \u001b[0mdir_path\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdirname\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrealpath\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m__file__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;32mexcept\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name '__file__' is not defined",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_14624/1297744843.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mexcept\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Could not find dir_path. If using jupyter notebook, ignore\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m     \u001b[0mtrain\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'/train.npy'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;36m255.0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m     \u001b[0mtest\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'/test.npy'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;36m255.0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\bendi\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\numpy\\lib\\npyio.py\u001b[0m in \u001b[0;36mload\u001b[1;34m(file, mmap_mode, allow_pickle, fix_imports, encoding)\u001b[0m\n\u001b[0;32m    415\u001b[0m             \u001b[0mown_fid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    416\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 417\u001b[1;33m             \u001b[0mfid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstack\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menter_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos_fspath\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"rb\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    418\u001b[0m             \u001b[0mown_fid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    419\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/train.npy'"
     ]
    }
   ],
   "source": [
    "# Finner 'veien' til der python filen er på din maskin, for å finne\n",
    "# train og test filene\n",
    "# Altså, må train og test filene være i samme mappe som denne fila\n",
    "try:\n",
    "    dir_path = os.path.dirname(os.path.realpath(__file__))\n",
    "except:\n",
    "    print(\"Could not find dir_path. If using jupyter notebook, ignore\")\n",
    "    train = np.load('train.npy')/255.0\n",
    "    test = np.load('test.npy')/255.0\n",
    "else:\n",
    "    train = np.load(dir_path + '/train.npy')/255.0\n",
    "    test = np.load(dir_path + '/test.npy')/255.0\n",
    "\n",
    "# Kvadratisk bildeplottingsfunksjon\n",
    "def plotimgs(imgs, nplot = 4):\n",
    "    \n",
    "    \"\"\"\n",
    "    Plotter de første nplot*nplot bildene i imgs på et nplot*nplot grid.\n",
    "    Antar høyde=bredde, og at bildene er lagret kolonnevis.\n",
    "    \n",
    "    Input:\n",
    "    imgs: (høyde=bredde,N) array som inneholder bildene. N > nplot**2\n",
    "    nplot: Heltall. nplot**2 bilder vil bli plottete\n",
    "    \n",
    "    Output:\n",
    "    Plot av de første nplot*nplot bildene i imgs på et nplot*nplot grid.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Henter antall bilder, og lengden på bildene \n",
    "    n = imgs.shape[1]\n",
    "    m = int(np.sqrt(imgs.shape[0]))\n",
    "\n",
    "    #sjekker om det er nok bilder til at de kan plottes\n",
    "    assert(n >= nplot**2), \"Need amount of data in matrix N >= nplot**2\"\n",
    "\n",
    "    # Initialiserer subplots\n",
    "    fig, axes = plt.subplots(nplot,nplot)\n",
    "\n",
    "    # Setter bakgrunnsfargen\n",
    "    plt.gcf().set_facecolor(\"lightgray\")\n",
    "\n",
    "    # Itererer over bildene\n",
    "    for idx in range(nplot**2):\n",
    "\n",
    "        # Bryter av hvis vi går utenfor arrayet\n",
    "        if idx >= n:\n",
    "            break\n",
    "\n",
    "        # Indekser\n",
    "        i = idx//nplot; j = idx%nplot\n",
    "\n",
    "        # Fjerner akse\n",
    "        axes[i,j].axis('off')\n",
    "        axes[i,j].imshow(imgs[:,idx].reshape((m,m)), cmap = \"gray\")\n",
    "    \n",
    "    # Plotter\n",
    "    fig.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "plotimgs(train[:,0,:], nplot=4)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\"\"\"\n",
    "T E K S T MARKDOWN!!!!\n",
    "Her ser vi de første 16 0-ene. nå bruker vi 0-ene\n",
    "T E K S T MARKDOWN!!!!\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "T E K S T MARKDOWN!!!!\n",
    "### Oppgave 2b\n",
    "Nå ser vi litt på deres SVD, egenskaper. <br>\n",
    "Vi regner ut deres SVD, og plotter deres 16 første dictionaries\n",
    "T E K S T MARKDOWN!!!!\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 1000 # Antall datapunkter\n",
    "c = 0 # Klasse\n",
    "d = 16 # 16 viktigste kolonner\n",
    "\n",
    "A = train[:,c,:n]\n",
    "W, H, S, FS, Vt = truncSVD(A, d)\n",
    "\n",
    "plotimgs(W, nplot = 4)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"\"\"\n",
    "T E K S T MARKDOWN!!!!\n",
    "Her ser vi de 16 første U-kolonnene. <br>\n",
    "Merk at disse ikke er de sammen som de første 0-bildene. <br>\n",
    "Vi ser at disse bildene inneholder viktige egenskaper som tallet 0 har, og at dens egenskaper blir mimdre og mindre. <br> representerende for tallet 0. <br>\n",
    "\n",
    "Vi ser på dens singulærvekotrer plottet logaritmisk vis for å mer innsikt i dem.\n",
    "T E K S T MARKDOWN!!!!\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.semilogy(S)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"\"\"\n",
    "T E K S T MARKDOWN!!!!\n",
    "Plotten vise oss at de aller første bildene har store singulæregenvektorer. <br>\n",
    "Den viser at de synker kraftig ned først, men etterpå går den ganske sakte nedover, med mange singulærvektorer som er ontrent det samme. <br>\n",
    "Hvis vi hadde større d, ville vi ha sett at den begynner å gå kraftig ned igjen, helt til at den krasjer til neglisjerbart 0. <br>\n",
    "    \n",
    "Dette forteller oss at singulærvektorene inneholder noen få viktige bilder, mange mindre viktige, men brukbare bilder, og en del bilder som er neglisjerbare. \n",
    "T E K S T MARKDOWN!!!!\n",
    "\"\"\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"\"\"\n",
    "T E K S T MARKDOWN!!!!\n",
    "Oppgace 2c\n",
    "Med vår SVD, tester vi dens trunktering på MNIST-datasettet\n",
    "Vi ser på fire ulike trunkterte svd, hver med økende grad av d valgte elementer.\n",
    "med disse dictionaris(ene) med ulike d, ser vi hva vi får når det projekteres på en vektore den er trent på, og en vektor den ikke er trent på\n",
    "T E K S T MARKDOWN!!!!\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def manytruncSVD(A, d):\n",
    "    \"\"\"\n",
    "    Gjør et svd med en LISTE av de d viktigste leddene i matrisen, altså flere trunkterte versjoner av vanlig SVD-regning.\n",
    "\n",
    "    Input:\n",
    "    A: Datasett-martise\n",
    "    d: En liste med antall U-kolonner/S-singulærvektorer/V-rader som skal brukes\n",
    "\n",
    "    Output:\n",
    "    W: En liste med dictionaries\n",
    "    (Bytt til manyW?)\n",
    "    S: Singulærvektorene til W. Brukes i 2d\n",
    "    \"\"\"\n",
    "\n",
    "    W = np.array([np.zeros((A.shape[0], A.shape[0]))] * len(d))\n",
    "\n",
    "    maxW = truncSVD(A, max(d))[0]\n",
    "\n",
    "    W[np.argmax(d)][:, :d[np.argmax(d)]] = maxW \n",
    "    d[np.argmax(d)] = 0\n",
    "\n",
    "    while max(d) != 0:\n",
    "        W[np.argmax(d)][:, :d[np.argmax(d)]] = maxW[:, :max(d)]\n",
    "        d[np.argmax(d)] = 0\n",
    "\n",
    "    return W, S\n",
    "\n",
    "def manyorthproj(W, B, antall):\n",
    "\n",
    "    I = [\"text\"] * antall\n",
    "\n",
    "    images = np.zeros((antall, A.shape[0]))\n",
    "\n",
    "    for i in range(antall):\n",
    "        images[i] = (np.transpose(orthproj(W[i], b)))\n",
    "        I[i] = images[i][np.newaxis, :]\n",
    "    return I\n",
    "\n",
    "def fiveplotter(W, B, antall):\n",
    "    \"\"\"I = image\"\"\"\n",
    "\n",
    "    I = manyorthproj(W, B, len(d))\n",
    "    zeros = np.zeros((1, A.shape[0]))\n",
    "    b = np.transpose(B)\n",
    "\n",
    "    totimage = np.transpose(np.concatenate((I[0], I[1], zeros, I[2], I[3], zeros, zeros, zeros, b), axis = 0))\n",
    "\n",
    "    plotimgs(totimage, 3)\n",
    "\n",
    "\"\"\"henter verdier\"\"\"\n",
    "A = train[:,c,:n]\n",
    "d = np.array([16, 32, 64, 128])\n",
    "W = manytruncSVD(A, d)[0]\n",
    "antall = 4\n",
    "\n",
    "\"\"\"første bilde\"\"\"\n",
    "\n",
    "b = train[:,0,:1]\n",
    "fiveplotter(W, b, antall)\n",
    "\"\"\"annen tall\"\"\"\n",
    "\n",
    "b = train[:,1,:1]\n",
    "fiveplotter(W, b, antall)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"\"\"\n",
    "T E K S T MARKDOWN!!!!\n",
    "Med en vektor dictionarien er trent opp med, ser vi at med høyere d, klarer den å projektere den originale 0 inntil sin dictionary bedre og bedre.\n",
    "Det samme skjer visuellt med bildet den ikke er trent på, men her er den alltid mye mer blurry enn den andre vektoren.\n",
    "Det er fordi dette 1-bildet projiserer den som om bildet var en 0, men det er den ikke.\n",
    "Da får vi blur mellom 0 og 1, der 1 viser sterkere jo høyere d vi får, men får masse artifater rundt eneren\n",
    "T E K S T MARKDOWN!!!!\n",
    "\"\"\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"\"\"\n",
    "T E K S T MARKDOWN!!!!\n",
    "Oppgave 2d\n",
    "For å sjekke bildenes sanne forskell med dictionaries(ene) finner vi deres distance til dem\n",
    "Vi bruker frobenius-norm for å finne distansene til disse bildematrisen og dictionaries(ene)\n",
    "T E K S T MARKDOWN!!!!\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Frobenium Norm Squared = FMS\n",
    "def FMS(A):\n",
    "    \n",
    "    \"\"\"\n",
    "    Regner ut Frobeniumn-normen til en matrise, kvadrert\n",
    "    \n",
    "    Input:\n",
    "    A: en matrise\n",
    "    \n",
    "    Output:\n",
    "    frobenium normen kvadrert\n",
    "    \"\"\"\n",
    "    \n",
    "    return sum(sum(A * A))\n",
    "\n",
    "# Henter verdier\n",
    "b = train[:,0,:1]\n",
    "d = np.arange(1, 784, 20)\n",
    "W, S = manytruncSVD(A, d)\n",
    "I = manyorthproj(W, b, len(d))\n",
    "\n",
    "# Setter opp en liste av distansene fra bildene og dictionarie(sene).\n",
    "matrisedist = np.zeros(len(d))\n",
    "\n",
    "# Itererer gjennom FMS, og printer logaritmisk dictionaries(enes) distanser fra første 0-bilde, med hver 20-ende d\n",
    "for i in range(len(d)):\n",
    "    matrisedist[i] = FMS(b[:,0] - I[i])\n",
    "plt.semilogy(matrisedist)\n",
    "\n",
    "# Itererer gjennom FMS, og printer logaritmisj dictionaries(enes) distanser fra første 1-bilde, med hver 20-ende d\n",
    "annettall = train[:,1,:1]\n",
    "for i in range(len(d)):\n",
    "    matrisedist[i] = FMS(annettall[:,0] - I[i])\n",
    "plt.semilogy(matrisedist)\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"\"\"\n",
    "T E K S T MARKDOWN!!!!\n",
    "Her ser vi at distansen fra 0-bildet synker mer og mer jo høyere d vi har.\n",
    "Dette gjør mening, siden maskinen har da flere vektorer den kan bruke til å bedre projektere bildet\n",
    "Vi ser også at den ligner veldig mye på bildets singulærverdier.\n",
    "Dette er fordi grafen av singulærverdiene er også basert på hvor høye d-verdiene er.\n",
    "Man kan si at verdiene til singulærvektorene forteller viktigheten til et spesifikt dictionary, altså hvor mye \"kraft den skal ha\",\n",
    "som betyr hvor mye den skal påvirke projiseringen, og dermed hvor forskjellig den nå er til det reelle bilde, altså avstanden fra b til projektert b.\n",
    "\n",
    "Det andre bildet, gir samme distanse uansett d, fordi dette bildet er ikke blitt trent opp i dictionarien,\n",
    "så unasett hva maskienn gjør, har den ingen dictionaries osm matcher det nye bildet.\n",
    "T E K S T MARKDOWN!!!!\n",
    "\"\"\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"\"\"\n",
    "T E K S T MARKDOWN!!!!\n",
    "Oppgave 2e\n",
    "Nå gjør vi det samme som vi hittil har gjort, men med den ikke-negative måten.\n",
    "Vi plotter deres projeksjoner først, og ser hva vi får av dem\n",
    "T E K S T MARKDOWN!!!!\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Henter verdier\n",
    "d = 32\n",
    "A = train[:,c,:n]\n",
    "nxn = 4\n",
    "\n",
    "#Henter test-bilder, og dictionaries\n",
    "Ann = A[:,np.random.choice(A.shape[1],nxn**2,replace=False)]\n",
    "Wpluss = A[:,np.random.choice(A.shape[1],d,replace=False)]\n",
    "\n",
    "# Projekterer bildene, og plotter dem\n",
    "proj = nnproj(Wpluss, Ann)[0]\n",
    "plotimgs(proj, nxn)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"\"\"\n",
    "T E K S T MARKDOWN!!!!\n",
    "Her ser vi tilfeldig valgte opptrente bilder, og tilfeldig valgte test-bilder.\n",
    "Vi ser at alle sammen er litt blurry i forhold til bildet med d = 32 på oppgave 2c,\n",
    "siden dictionarisene er ikke sortert fra best til verst, men er heller plukket frem tilfeldig.\n",
    "T E K S T MARKDOWN!!!!\n",
    "\"\"\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"\"\"\n",
    "T E K S T MARKDOWN!!!!\n",
    "Oppgave 2f\n",
    "Nå sjekker vi distansene vi får med høyere d, og ulike bilder, med den ikke-negative metoden.\n",
    "T E K S T MARKDOWN!!!!\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gjør flere ikke-negative projiseringer \n",
    "def manynnproj(Wpluss, B, d):\n",
    "\n",
    "    proj = np.array([np.zeros((A.shape[0], 1))] * len(d))\n",
    "\n",
    "    proj[np.argmax(d)]= nnproj(Wpluss, b)[0]\n",
    "    d[np.argmax(d)] = 0\n",
    "\n",
    "\n",
    "    while max(d) != 0:\n",
    "        Wpluss = Wpluss[:,np.random.choice(Wpluss.shape[1],max(d),replace=False)]\n",
    "        proj[np.argmax(d)] = nnproj(Wpluss, b)[0]\n",
    "        d[np.argmax(d)] = 0\n",
    "\n",
    "    return proj\n",
    "\n",
    "d = np.logspace(1,3,10, dtype = np.int64)\n",
    "\n",
    "A = train[:,c,:n]\n",
    "Wpluss = A[:,np.random.choice(A.shape[1],max(d),replace=False)]\n",
    "\n",
    "b = train[:,0,:1]\n",
    "\n",
    "\n",
    "manyproj = manynnproj(Wpluss, b, d)\n",
    "\n",
    "print(manyproj.shape)\n",
    "\"\"\"fiks det messet ^^. gosh >.<\"\"\"\n",
    "\n",
    "\n",
    "\"\"\"bildene, som er projisert\"\"\"\n",
    "\n",
    "matrisedist = np.zeros(len(d))\n",
    "\n",
    "\n",
    "for i in range(len(d)):\n",
    "    matrisedist[i] = FMS(b - manyproj[i])\n",
    "\n",
    "\"\"\"bruk print(a.shape) for å finne ut om det er i en matrise. da funker FMS\"\"\"\n",
    "\n",
    "\n",
    "plt.semilogy(matrisedist)\n",
    "\n",
    "\n",
    "annettall = train[:,1,:1]\n",
    "\n",
    "for i in range(len(d)):\n",
    "    matrisedist[i] = FMS(annettall - manyproj[i])\n",
    "\n",
    "plt.semilogy(matrisedist)\n",
    "plt.show()\n",
    "\"\"\"tilfelidgheter kommer her ja. masse ved slutten\"\"\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"\"\"\n",
    "T E K S T MARKDOWN!!!!\n",
    "I forhold til plotten fra 2d, ser vi at distansen fra 0-bildet synker først mer og mer jo høyere d vi har.\n",
    "Men så ser vi at den blir ganske tilfelidg ved de største d, og at det ikke er alltid at distansen er lav.\n",
    "Det er fordi H-matrisen som konvergerer ved nnproj er nå så stor at maxiter = 50 er for lite til at den kan skikkelig konvergere.\n",
    "Dette skaper tilfeldighetene, ettersom H vil nå være preget av tilfeldigheter fra randint.\n",
    "\n",
    "Det andre bildet, gir samme distanse uansett d, fordi dette bildet er ikke blitt trent opp i dictionarien; selv med den ikke-negative metoden.\n",
    "T E K S T MARKDOWN!!!!\n",
    "\"\"\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\"\"\"\n",
    "T E K S T MARKDOWN!!!!\n",
    "Oppgave 3a lets go\n",
    "T E K S T MARKDOWN!!!!\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3633f438634194677d5a56fa82856b886ad79a013c3710805264d16212529561"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
